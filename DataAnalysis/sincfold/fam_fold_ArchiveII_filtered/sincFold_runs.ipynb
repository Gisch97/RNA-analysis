{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df656c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- Configuración global ---\n",
    "BASE_PATHS = {\n",
    "    \"fam-sim\": \"models/fam-sim/2000_steps/\",\n",
    "    \"rnadist-100\": \"models/rnadist/dist_100/2000_steps/\",\n",
    "    \"rnadist-200\": \"models/rnadist/dist_200/2000_steps/\",\n",
    "    \"rnadist-400\": \"models/rnadist/dist_400/2000_steps/\",\n",
    "}\n",
    "\n",
    "\n",
    "SAVE_PATH = \"results/tables/2000s/\"\n",
    "SAVE_FILE = \"rnadist_2000s_f1_post_test.csv\"\n",
    "\n",
    "### Verificar el nombre de test.csv (5/10e)\n",
    "### Revisar si hay que agregar epochs en (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c684cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source      fam-sim  rnadist-100  rnadist-200  rnadist-400\n",
      "fam                                                       \n",
      "16s           0.322        0.340        0.360        0.381\n",
      "23s           0.423        0.432        0.425        0.449\n",
      "5s            0.417        0.355        0.487        0.423\n",
      "RNaseP        0.345        0.419        0.370        0.454\n",
      "grp1          0.365        0.303        0.276        0.388\n",
      "srp           0.236        0.209        0.286        0.250\n",
      "tRNA          0.434        0.589        0.669        0.646\n",
      "telomerase    0.211        0.177        0.115        0.218\n",
      "tmRNA         0.320        0.356        0.333        0.359\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Utilidades de carga de datos ---\n",
    "def load_csv_if_exists(csv_path: str, warn_msg: str) -> pd.DataFrame | None:\n",
    "    \"\"\"Carga un CSV si existe; muestra un warning si no.\"\"\"\n",
    "    if os.path.isfile(csv_path):\n",
    "        return pd.read_csv(csv_path)\n",
    "    else:\n",
    "        print(f\"[WARN] {warn_msg}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def collect_results_from_path(\n",
    "    path: str, source: str\n",
    ") -> tuple[list[pd.DataFrame], list[pd.DataFrame]]:\n",
    "    \"\"\"Recorre un path y carga todos los CSVs de entrenamiento y test.\"\"\"\n",
    "    train_logs, test_results = [], []\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[WARN] Ruta no encontrada: {path}\")\n",
    "        return train_logs, test_results\n",
    "\n",
    "    for fam in os.listdir(path):\n",
    "        fam_path = os.path.join(path, fam)\n",
    "        train_csv = os.path.join(fam_path, \"train_log.csv\")\n",
    "        test_csv = os.path.join(fam_path, \"test_2000steps.csv\")\n",
    "\n",
    "        df_train = load_csv_if_exists(\n",
    "            train_csv, f\"No se encontró train_log.csv en {fam_path}\"\n",
    "        )\n",
    "        if df_train is not None:\n",
    "            df_train[\"fam\"] = fam\n",
    "            df_train[\"source\"] = source\n",
    "            train_logs.append(df_train)\n",
    "\n",
    "        df_test = load_csv_if_exists(\n",
    "            test_csv, f\"No se encontró test_2000steps.csv en {fam_path}\"\n",
    "        )\n",
    "        if df_test is not None:\n",
    "            df_test[\"fam\"] = fam\n",
    "            df_test[\"source\"] = source\n",
    "            test_results.append(df_test)\n",
    "\n",
    "    return train_logs, test_results\n",
    "\n",
    "\n",
    "def load_all_results(base_paths: dict) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Carga y concatena todos los resultados desde las rutas base.\"\"\"\n",
    "    all_train_logs, all_test_results = [], []\n",
    "\n",
    "    for source, path in base_paths.items():\n",
    "        train_logs, test_results = collect_results_from_path(path, source)\n",
    "        all_train_logs.extend(train_logs)\n",
    "        all_test_results.extend(test_results)\n",
    "\n",
    "    train_df = pd.concat(all_train_logs, ignore_index=True)\n",
    "    test_df = pd.concat(all_test_results, ignore_index=True)\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# --- 2. Preprocesamiento ---\n",
    "def adjust_epochs(df: pd.DataFrame, epoch_offset: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"Ajusta los números de epoch sumando un offset.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"epoch\"] += epoch_offset\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 3. Agregación y resumen ---\n",
    "def summarize_metric(df: pd.DataFrame, metric: str) -> pd.DataFrame:\n",
    "    \"\"\"Agrega resultados por familia y fuente usando la métrica dada.\"\"\"\n",
    "    summary = df.groupby([\"fam\", \"source\"])[metric].mean().reset_index()\n",
    "    return summary\n",
    "\n",
    "\n",
    "def build_pivot_table(\n",
    "    summary_df: pd.DataFrame, column_order: list[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Construye una tabla pivot ordenada por las columnas especificadas.\"\"\"\n",
    "    pivot = summary_df.pivot(\n",
    "        index=\"fam\", columns=\"source\", values=summary_df.columns[-1]\n",
    "    )\n",
    "    return pivot[column_order]\n",
    "\n",
    "\n",
    "# --- 4. Pipeline principal ---\n",
    "def main(metric: str, column_order: list[str]):\n",
    "    # Carga resultados\n",
    "    train_logs_df, test_results_df = load_all_results(BASE_PATHS)\n",
    "\n",
    "    # Preprocesa\n",
    "    train_logs_df = adjust_epochs(train_logs_df, 0)\n",
    "\n",
    "    # Agrega y muestra resultados\n",
    "    summary_df = summarize_metric(test_results_df, metric)\n",
    "    pivot_df = build_pivot_table(summary_df, column_order)\n",
    "    print(pivot_df)\n",
    "    return pivot_df\n",
    "\n",
    "\n",
    "# --- Ejecución ---\n",
    "if __name__ == \"__main__\":\n",
    "    metric_to_use = \"f1_post\"\n",
    "    desired_column_order = list(BASE_PATHS.keys())\n",
    "    pivot_table = main(metric_to_use, desired_column_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e41d0b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.to_csv(SAVE_PATH + SAVE_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
